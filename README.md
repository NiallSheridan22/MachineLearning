# Project Overview
In this project which is credit card fraud detection with machine learning. The question that is trying to be anwsered about the project is - Can ensemble machine learning be more accurate than a single supervised learning algorithm for Credit Card Fraud Detection. To do this there will be different algorithms used and tested to see how they score themseleves as well as that there will be supervised algorithms combined to see how the ensmeble compare to the singular algorithms.

# Installation
Software requirements -  Python it is open-source software with a wide range of installable libraries, including SciPy, NumPy, and many more that may be used to support machine learning. There are also Visualisation libraries that can help like Matplotlib and Seaborn. Google Colab for writing the code for the project.

Hardware requirements - There are hardware requirements required throughout the project but very little, a pc and laptop will be used.

# Usage
You can access the code files in the github. You are able to download them and open them in google Colab if you like and see the code running. The files have already been ran so you can see the output from the code.

# Data
There was several steps taken to get the data ready.  Pre-processing
 Pre-processing data aims to convert raw data into a format that will be more practical and useful for further processing procedures to be run on a certain machine learning technique that will provide no issues. Pre-processing was required as there was columns that had to be dropped and data that needs to be normalised to group similar values into one common value.

Data Cleaning
Data cleaning is the process of removing erroneous, damaged, badly structured, duplicate, or incomplete data from a dataset. When combining various data sources, there are several possibilities for data to be duplicated or improperly classified. The type of data cleaning that will be done on the credit card fraud data set will be removing duplicates, fixing errors, missing values, and removing irrelevant data.

Data Mining 
Data mining is discovering patterns and valuable information from large data. Data mining has several steps data classification, prediction of outcomes, forecasting the result, Data clustering, affinity grouping, and description and profiling are some examples. Data mining will work with different algorithms and techniques to large data sets into useful information, the types of data techniques that will be used on the dataset will be bagging, boosting, and stacking.

# Results

# Future Work

# Contact
